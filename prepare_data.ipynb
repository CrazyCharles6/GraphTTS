{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries, metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-18T06:01:56.263558Z",
     "start_time": "2019-12-18T06:01:51.717351Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lyh/anaconda3/envs/LYH/lib/python3.7/site-packages/librosa/util/decorators.py:9: NumbaDeprecationWarning: \u001b[1mAn import was requested from a module that has moved location.\n",
      "Import requested from: 'numba.decorators', please update to use 'numba.core.decorators' or pin to Numba version 0.48.0. This alias will not be present in Numba version 0.50.0.\u001b[0m\n",
      "  from numba.decorators import jit as optional_jit\n",
      "/home/lyh/anaconda3/envs/LYH/lib/python3.7/site-packages/librosa/util/decorators.py:9: NumbaDeprecationWarning: \u001b[1mAn import was requested from a module that has moved location.\n",
      "Import of 'jit' requested from: 'numba.decorators', please update to use 'numba.core.decorators' or pin to Numba version 0.48.0. This alias will not be present in Numba version 0.50.0.\u001b[0m\n",
      "  from numba.decorators import jit as optional_jit\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import librosa\n",
    "from librosa.filters import mel as librosa_mel_fn\n",
    "import pickle as pkl\n",
    "import IPython.display as ipd\n",
    "from tqdm.notebook import tqdm\n",
    "import torch\n",
    "import numpy as np\n",
    "import codecs\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from g2p_en import G2p\n",
    "from text import *\n",
    "from text import cmudict\n",
    "from text.cleaners import custom_english_cleaners\n",
    "from text.symbols import symbols\n",
    "\n",
    "# Mappings from symbol to numeric ID and vice versa:\n",
    "symbol_to_id = {s: i for i, s in enumerate(symbols)}\n",
    "id_to_symbol = {i: s for i, s in enumerate(symbols)}\n",
    "\n",
    "csv_file = '/media/disk1/lyh/LJSpeech-1.1/metadata.csv'\n",
    "root_dir = '/media/disk1/lyh/LJSpeech-1.1/wavs'\n",
    "data_dir = '/media/disk1/lyh/LJSpeech-1.1/preprocessed'\n",
    "\n",
    "g2p = G2p()\n",
    "metadata={}\n",
    "with codecs.open(csv_file, 'r', 'utf-8') as fid:\n",
    "    for line in fid.readlines():\n",
    "        id, _, text = line.split(\"|\")\n",
    "        \n",
    "        clean_char = custom_english_cleaners(text.rstrip())\n",
    "        clean_phone = []\n",
    "        for s in g2p(clean_char.lower()):\n",
    "            if '@'+s in symbol_to_id:\n",
    "                clean_phone.append('@'+s)\n",
    "            else:\n",
    "                clean_phone.append(s)\n",
    "        \n",
    "        metadata[id]={'char':clean_char,\n",
    "                     'phone':clean_phone}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from layers import TacotronSTFT\n",
    "stft = TacotronSTFT()\n",
    "\n",
    "def text2seq(text):\n",
    "    sequence=[symbol_to_id['^']]\n",
    "    sequence.extend([symbol_to_id[c] for c in text])\n",
    "    sequence.append(symbol_to_id['~'])\n",
    "    return sequence\n",
    "\n",
    "def create_adjacency_matrix(char_seq):\n",
    "    n_nodes=len(char_seq)\n",
    "    n_edge_types=3\n",
    "    \n",
    "    a = np.zeros([n_edge_types, n_nodes, n_nodes], dtype=np.int)\n",
    "    \n",
    "    a[0] = np.eye(n_nodes, k=1, dtype=int) + np.eye(n_nodes, k=-1, dtype=int)\n",
    "    a[2] = 1\n",
    "    \n",
    "    white_spaces = (char_seq==symbol_to_id[' ']).nonzero()\n",
    "    start = torch.cat([torch.tensor([0]), white_spaces[1:].view(-1)])\n",
    "    end = torch.cat([white_spaces[1:].view(-1), torch.tensor([n_nodes])])\n",
    "    for i in range(len(start)):\n",
    "        a[1, start[i]:end[i], start[i]:end[i]]=1\n",
    "    \n",
    "    # a = np.concatenate((a, a), axis=0)\n",
    "    # a = np.transpose(a, (1, 0, 2)).reshape(n_nodes, n_nodes*n_edge_types*2)\n",
    "    return a\n",
    "\n",
    "def get_mel(filename):\n",
    "    wav, sr = librosa.load(filename, sr=22050)\n",
    "    wav = torch.FloatTensor(wav.astype(np.float32))\n",
    "    melspec = stft.mel_spectrogram(wav.unsqueeze(0))\n",
    "    return melspec.squeeze(0), wav\n",
    "\n",
    "def save_file(fname):\n",
    "    wav_name = os.path.join(root_dir, fname) + '.wav'\n",
    "    text = metadata[fname]['char']\n",
    "    char_seq = torch.LongTensor( text2seq(metadata[fname]['char']) )\n",
    "    phone_seq = torch.LongTensor( text2seq(metadata[fname]['phone']) )\n",
    "    adj_matrix = create_adjacency_matrix(char_seq)\n",
    "    melspec, wav = get_mel(wav_name)\n",
    "        \n",
    "    with open(f'{data_dir}/char_seq/{fname}_sequence.pkl', 'wb') as f:\n",
    "        pkl.dump(char_seq, f)\n",
    "    with open(f'{data_dir}/phone_seq/{fname}_sequence.pkl', 'wb') as f:\n",
    "        pkl.dump(phone_seq, f)\n",
    "    with open(f'{data_dir}/adj_matrix/{fname}_adj_matrix.pkl', 'wb') as f:\n",
    "        pkl.dump(adj_matrix, f)\n",
    "    with open(f'{data_dir}/melspectrogram/{fname}_melspectrogram.pkl', 'wb') as f:\n",
    "        pkl.dump(melspec, f)\n",
    "        \n",
    "    return text, char_seq, phone_seq, adj_matrix, melspec, wav"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save and Inspect Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-12-18T06:01:23.402Z"
    },
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for k in tqdm(metadata.keys()):\n",
    "    text, char_seq, phone_seq, adj_matrix, melspec, wav = save_file(k)\n",
    "    if k == 'LJ001-0019':\n",
    "        print(\"Text:\")\n",
    "        print(text)\n",
    "        print()\n",
    "        print(\"Melspectrogram:\")\n",
    "        plt.figure(figsize=(16,4))\n",
    "        plt.imshow(melspec, aspect='auto', origin='lower')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34e6927c94f245669e35ed76ef0fbff0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=13100.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lyh/anaconda3/envs/LYH/lib/python3.7/site-packages/torch/storage.py:34: FutureWarning: pickle support for Storage will be removed in 1.5. Use `torch.save` instead\n",
      "  warnings.warn(\"pickle support for Storage will be removed in 1.5. Use `torch.save` instead\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def text2seq(text):\n",
    "    sequence=[symbol_to_id['^']]\n",
    "    sequence.extend([symbol_to_id[c] for c in text])\n",
    "    sequence.append(symbol_to_id['~'])\n",
    "    return sequence\n",
    "\n",
    "def create_adjacency_matrix(char_seq):\n",
    "    n_nodes=len(char_seq)\n",
    "    n_edge_types=3\n",
    "    \n",
    "    a = np.zeros([n_edge_types, n_nodes, n_nodes], dtype=np.int)\n",
    "    \n",
    "    a[0] = np.eye(n_nodes, k=1, dtype=int) + np.eye(n_nodes, k=-1, dtype=int)\n",
    "    a[2] = 1\n",
    "    \n",
    "    white_spaces = (char_seq==symbol_to_id[' ']).nonzero()\n",
    "    start = torch.cat([torch.tensor([0]), white_spaces[1:].view(-1)])\n",
    "    end = torch.cat([white_spaces[1:].view(-1), torch.tensor([n_nodes])])\n",
    "    for i in range(len(start)):\n",
    "        a[1, start[i]:end[i], start[i]:end[i]]=1\n",
    "    \n",
    "    # a = np.concatenate((a, a), axis=0)\n",
    "    # a = np.transpose(a, (1, 0, 2)).reshape(n_nodes, n_nodes*n_edge_types*2)\n",
    "    return a\n",
    "\n",
    "def save_file(fname):\n",
    "    wav_name = os.path.join(root_dir, fname) + '.wav'\n",
    "    text = metadata[fname]['char']\n",
    "    char_seq = torch.LongTensor( text2seq(metadata[fname]['char']) )\n",
    "    adj_matrix = torch.LongTensor(create_adjacency_matrix(char_seq))\n",
    "        \n",
    "    with open(f'{data_dir}/adj_matrix/{fname}_adj_matrix.pkl', 'wb') as f:\n",
    "        pkl.dump(adj_matrix, f)\n",
    "\n",
    "\n",
    "for k in tqdm(metadata.keys()):\n",
    "    save_file(k)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:LYH] *",
   "language": "python",
   "name": "conda-env-LYH-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
